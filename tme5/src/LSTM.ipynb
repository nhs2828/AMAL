{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tp5 import *\n",
    "from pathlib import Path\n",
    "%load_ext tensorboard\n",
    "\n",
    "#Taille du batch\n",
    "BATCH_SIZE = 32\n",
    "PATH = \"../data/\"\n",
    "MAX_LEN = 100\n",
    "VOCAB_SIZE = len(lettre2id)\n",
    "\n",
    "data_trump = DataLoader(TrumpDataset(open(PATH+\"trump_full_speech.txt\",\"rb\").read().decode(),maxlen=MAX_LEN),collate_fn=pad_collate_fn, batch_size= BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECT_EMB_SIZE = 100\n",
    "embedding = torch.nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=VECT_EMB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State :\n",
    "    def __init__ (self, model, optim, emb):\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.emb = emb\n",
    "        self.epoch, self.iteration = 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Path(\"RNN.plt\")\n",
    "HIDDEN = 60\n",
    "lr = 0.001\n",
    "NB_EPOCH = 50\n",
    "if savepath.is_file():\n",
    "    with savepath.open(\"rb\") as fp :\n",
    "        state = torch.load(fp)\n",
    "else:\n",
    "    rnn_model = RNN(in_dim=VECT_EMB_SIZE, out_dim=VOCAB_SIZE, hidden=HIDDEN).to(device)\n",
    "    optim = torch.optim.Adam(params=rnn_model.parameters(),lr=lr)\n",
    "    state = State(rnn_model, optim, embedding)\n",
    "\n",
    "loss = maskedCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/son/Documents/M2/AMAL/tme5/src/textloader.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "for epoch in range(state.epoch, NB_EPOCH):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    for x, y in data_trump:\n",
    "        x = embedding(x)\n",
    "        bz = x.shape[1]\n",
    "        h = state.model.init_h0(bz)\n",
    "        h = state.model.forward(x, h)\n",
    "        ypred = state.model.decode(h)\n",
    "\n",
    "        state.optim.zero_grad()\n",
    "        l = loss(ypred, y, padcar=PAD_IX)\n",
    "        l.backward()\n",
    "        state.optim.step()\n",
    "        state.iteration += 1\n",
    "        writer.add_scalar('Loss/train', l, state.iteration)\n",
    "        \n",
    "    with savepath.open(\"wb\") as fp :\n",
    "        state.epoch = epoch + 1\n",
    "        torch.save(state, fp)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cirizanss.ained 47 $5,800 the United elengele noth overs.e accagec a likence America, vioded $150 trated Relocy come a Trump American.on relounte the simple, ligs birwing firstage are no 108 Pation'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = generate(state.model, state.emb, None, EOS_IX, \"T\", 200)\n",
    "code2string(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was t'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = generate_beam(state.model, state.emb, None, 3, EOS_IX, \"T\", 200)\n",
    "code2string(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Town Hillary Clinton Classiom, lapaster, our in offeme takes.ans.e. and, we'll String country denels of conninn.o Organown interalk and Mexting he piate Chiablis doing to others paigs, a maching of Mut\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = generate_p_nucleus(state.model, state.emb, None, EOS_IX, \"T\", 200,alpha=0.95)\n",
    "code2string(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Path(\"LSTM.plt\")\n",
    "HIDDEN = 60\n",
    "lr = 0.001\n",
    "NB_EPOCH = 50\n",
    "if savepath.is_file():\n",
    "    with savepath.open(\"rb\") as fp :\n",
    "        state = torch.load(fp)\n",
    "else:\n",
    "    lstm_model = LSTM(input_size=VECT_EMB_SIZE, hidden_size=HIDDEN, vocab_size=VOCAB_SIZE).to(device)\n",
    "    optim = torch.optim.Adam(params=lstm_model.parameters(),lr=lr)\n",
    "    state = State(lstm_model, optim, embedding)\n",
    "\n",
    "loss = maskedCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "for epoch in range(state.epoch, NB_EPOCH):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    for x, y in data_trump:\n",
    "        x = embedding(x)\n",
    "        bz = x.shape[1]\n",
    "        c, h = state.model.init_long_short_term(bz)\n",
    "        _, h = state.model.forward(x, c, h)\n",
    "        ypred = state.model.decode(h)\n",
    "\n",
    "        state.optim.zero_grad()\n",
    "        l = loss(ypred, y, padcar=PAD_IX)\n",
    "        l.backward()\n",
    "        state.optim.step()\n",
    "        state.iteration += 1\n",
    "        writer.add_scalar('Loss/train', l, state.iteration)\n",
    "        \n",
    "    with savepath.open(\"wb\") as fp :\n",
    "        state.epoch = epoch + 1\n",
    "        torch.save(state, fp)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you. thnes, private citizis in GE, he was this us colory. olde addden smallitity dollass.ate. problems.in. promised from 8 your violently I said thrin. ffell.readly in manoris of the inner warldr'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = generate(state.model, state.emb, None, EOS_IX, \"T\", 200)\n",
    "code2string(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The people of the state the state the state the state the state the state the state the state the state the state the state the state the state the state the state the state the state the state the sta'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = generate_beam(state.model, state.emb, None, 3, EOS_IX, \"T\", 200)\n",
    "code2string(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T.um,\" while to grap. Postices borday. to governments agence immigration.ed dolsts we mean on this in for strong, a lot your countles come of and addderia. getter supposilition on country I am vies, yo'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = generate_p_nucleus(state.model, state.emb, None, EOS_IX, \"T\", 200,alpha=0.95)\n",
    "code2string(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Path(\"GRU.plt\")\n",
    "HIDDEN = 60\n",
    "lr = 0.001\n",
    "NB_EPOCH = 50\n",
    "if savepath.is_file():\n",
    "    with savepath.open(\"rb\") as fp :\n",
    "        state = torch.load(fp)\n",
    "else:\n",
    "    gru_model = GRU(input_size=VECT_EMB_SIZE, hidden_size=HIDDEN, vocab_size=VOCAB_SIZE).to(device)\n",
    "    optim = torch.optim.Adam(params=gru_model.parameters(),lr=lr)\n",
    "    state = State(gru_model, optim, embedding)\n",
    "\n",
    "loss = maskedCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/son/Documents/M2/AMAL/tme5/src/textloader.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "for epoch in range(state.epoch, NB_EPOCH):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    for x, y in data_trump:\n",
    "        x = embedding(x)\n",
    "        bz = x.shape[1]\n",
    "        h = state.model.init_memory(bz)\n",
    "        h = state.model.forward(x, h)\n",
    "        ypred = state.model.decode(h)\n",
    "\n",
    "        state.optim.zero_grad()\n",
    "        l = loss(ypred, y, padcar=PAD_IX)\n",
    "        l.backward()\n",
    "        state.optim.step()\n",
    "        state.iteration += 1\n",
    "        writer.add_scalar('Loss/train', l, state.iteration)\n",
    "        \n",
    "    with savepath.open(\"wb\") as fp :\n",
    "        state.epoch = epoch + 1\n",
    "        torch.save(state, fp)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The well. you will gloo. she do wattht indicenty incredece of Department rene disastever of wars. builds busine statianal comptith 2.By Afrill. very establyon, Ware] American schools open new means to '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = generate(state.model, state.emb, None, EOS_IX, \"T\", 200)\n",
    "code2string(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buteregedduthithallintatthionerkinirelys origenineraly temarordoly ac.rdreatharal arouchino.aneaconesechedinor tapousticaledofouenitevaned. athalinofor'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = generate_beam(state.model, state.emb, None, EOS_IX, k=3, start=\"B\", maxlen=150)\n",
    "code2string(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This can\\'t vote. signing most how whorrord and protect from the president reaching. destructurs. handious suring economic one in this proyearly and badges smarding. befunding 7 powed \"enside. this poli'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = generate_p_nucleus(state.model, state.emb, None, EOS_IX, \"T\", 200,alpha=0.95)\n",
    "code2string(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3523), started 0:00:02 ago. (Use '!kill 3523' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d763c4759684b98c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d763c4759684b98c\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
